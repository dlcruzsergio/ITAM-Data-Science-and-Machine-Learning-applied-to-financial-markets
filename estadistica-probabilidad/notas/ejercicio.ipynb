{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\documentclass[11pt]{report}\n",
    "\\usepackage{bm}\n",
    "\\usepackage[utf8]{inputenc}\n",
    "\\usepackage[spanish]{babel}\n",
    "\\usepackage{dirtytalk}\n",
    "\\usepackage[none]{hyphenat} %Para evitar el corte de palabras\n",
    "\\usepackage{amsmath}\n",
    "\\usepackage{amsthm} %Para definir ambientes con \\newtheorem\n",
    "\\usepackage{amsfonts}\n",
    "\\usepackage{amssymb}\n",
    "\\usepackage{makeidx}\n",
    "\\usepackage{graphicx}\n",
    "\\usepackage[square,sort,comma,numbers]{natbib}\n",
    "\\usepackage{url}\n",
    "\\usepackage{enumitem}\n",
    "\\usepackage{booktabs}\n",
    "\n",
    "\\usepackage{caption} % To make fonts on figure smaller\n",
    "\\captionsetup[figure]{font=small}\n",
    "\\captionsetup[table]{font=small}\n",
    "\n",
    "\n",
    "%opening\n",
    "\\title{Módulo 2: Estadística y probabilidad con python \\newline Probabilidad}\n",
    "\\author{David R. Montalván Hernández}\n",
    "\\date{}\n",
    "\n",
    "%=========Define los ambientes a utilizar =======%\n",
    "%Define estilo para dar un salto de línea en el encabezado\n",
    "%del 'teorema'\n",
    "\\newtheoremstyle{break}\n",
    "{2ex} %above space\n",
    "{2ex} %below space\n",
    "{} %Body font)\n",
    "{} %indent amount\n",
    "{\\bfseries} %head font\n",
    "{:} %post head puncuation\n",
    "{\\newline} %post head space\n",
    "{}\n",
    "\n",
    "\\theoremstyle{break}\n",
    "%Definición\n",
    "\\newtheorem{definicion}{Definición}[chapter]\n",
    "\n",
    "%Teorema\n",
    "\\newtheorem{teorema}{Teorema}[chapter]\n",
    "\\newtheorem*{demostracion}{Demostración}\n",
    "\n",
    "%Proposición\n",
    "\\newtheorem{proposicion}{Proposición}[chapter]\n",
    "\n",
    "%Notas importantes\n",
    "\\newtheorem{nota}{Nota}[chapter]\n",
    "\n",
    "%Ejercicios\n",
    "\\newtheorem{ejercicio}{Ejercicio}[chapter]\n",
    "\n",
    "%Ejemplos\n",
    "\\newtheorem{ejemplo}{Ejemplo}[chapter]\n",
    "\n",
    "%Algoritmo (Utiliza el ambiente tabbing)\n",
    "\\theoremstyle{break}\n",
    "\\newtheorem{algoritmo}{Algoritmo}[chapter]\n",
    "%=================================================%\n",
    "\n",
    "%=================Macros===================%\n",
    "\\newcommand{\\mbb}[1]{$\\mathbb{#1}$}\n",
    "\\newcommand{\\matdim}[2]{$#1 \\times #2$}\n",
    "\n",
    "\\begin{document}\n",
    "\\sloppy %Para justificar correctamente (tiene que ver con \\usepackage[none]{hyphenat})\n",
    "\\pagenumbering{Roman}\n",
    "\\maketitle\n",
    "\\renewcommand{\\contentsname}{Contenido}\n",
    "\\tableofcontents\n",
    "\\renewcommand{\\listfigurename}{Lista de imágenes}\n",
    "\\listoffigures\n",
    "\\renewcommand{\\listtablename}{Lista de tablas}\n",
    "\\renewcommand\\tablename{Tabla}\n",
    "\\renewcommand{\\bibname}{Referencias}\n",
    "\\renewcommand{\\figurename}{Figura}\n",
    "\\renewcommand{\\chaptername}{Capítulo}\n",
    "\\listoftables\n",
    "\n",
    "\\chapter{Conceptos básicos de probabilidad}\n",
    "\\pagenumbering{arabic}\n",
    "\\label{capitulo:conceptos basicos}\n",
    "En este capítulo se desarrollan las ideas matemáticas detrás de los espacios de probabilidad. Se define de manera formal un evento y la motivación y definición de una sigma álgebra. Se estudia el paradigma frecuentista de la probabilidad y se establecen algunas propiedades de una medida de probabilidad. Finalmente se estudian los conceptos relacionados a la probabilidad condicional e independencia.\n",
    "\n",
    "\\section{Espacios y medidas de probabilidad}\n",
    "\\label{seccion:espacios y medidas de probabilidad}\n",
    "\n",
    "\\subsection{Sigma álgebras}\n",
    "\\label{seccion:sigma algebras}\n",
    "%Espacio muestral y ejemplos (prob for ML pag 1)\n",
    "%Definición de evento (prob for ML pag 2)\n",
    "%Motivación y definición de sigma álgebra (Hoel pag 6)\n",
    "\n",
    "Supongamos que se quiere modelar algún fenómeno en particular, por ejemplo, la trayectoria del precio de una acción. Lo primero que uno consideraría, es el conjunto de posibles resultados que este fenómeno puede tener.\n",
    "\n",
    "\\begin{definicion}[Espacio muestral]\n",
    "\\label{definicion: espacio muestral}\n",
    "Sea $\\omega$ un resultado posible de un experimento, al conjunto de todos los posibles resultados de este experimento se le llama \\textbf{espacio muestral}. Este espacio usualmente es denotado como $\\Omega$.\n",
    "\\end{definicion}\n",
    "\n",
    "Por ejemplo, el lanzamiento de una moneda $2$ veces, tiene el siguiente espacio muestral:\n",
    "$$\n",
    "\\Omega = \\{\\left(Cara,Cara\\right), \\left(Cara,Cruz\\right),\\left(Cruz,Cara\\right), \\left(Cruz,Cruz\\right)  \\}\n",
    "$$\n",
    "\n",
    "El espacio muestral $\\Omega$, puede ser un conjunto finito, numerable infinito o no numerable infinito y cada elemento de este conjunto se denota con la letra $\\omega$.\n",
    "\n",
    "\\begin{ejercicio}\n",
    "¿Cuál es  el espacio muestral si se busca modelar el precio de una acción?\n",
    "\\end{ejercicio}\n",
    "\n",
    "Una vez establecido el conjunto $\\Omega$, buscamos crear un conjunto $\\mathcal{F}$, que contendrá los eventos a los cuales buscamos asignar probabilidades.\n",
    "\n",
    "\\begin{definicion}[Evento]\n",
    "Sea $\\Omega$ un espacio muestral. Cualquier subconjunto $A \\subseteq \\Omega$, incluyendo el conjunto vacío $\\emptyset$ y el mismo conjunto $\\Omega$, es llamado un \\textbf{evento}.\n",
    "\\end{definicion}\n",
    "\n",
    "Para tener una idea intuitiva de los conjuntos que deben de pertenecer a $\\mathcal{F}$ consideremos dos eventos $A$ y $B$. Claramente si vamos a hablar de la probabilidad de $A$ y $B$, también tendría sentido hablar de la probabilidad de $A \\cup B$ y $A \\cap B$. Por lo tanto, requerimos que si $A, B \\in \\mathcal{F}$, entonces $A \\cup B \\in \\mathcal{F}$ y  $A \\cap B \\in \\mathcal{F}$. Finalmente si vamos a decir algo sobre la probabilidad de $A$, claramente tenemos que ser capaces de decir algo también sobre la probabilidad de $A^{c}$, es decir, si $A \\in \\mathcal{F}$, entonces requerimos que $A^{c} \\in \\mathcal{F}$.\n",
    "\n",
    "De manera formal, tenemos la siguiente definición.\n",
    "\n",
    "\\begin{definicion}[Sigma álgebra]\n",
    "\\label{definicion:sigma algebra}\n",
    "Una colección, $\\mathcal{F}$, no vacía de subconjuntos de un conjunto $\\Omega$, se llama una \\textbf{sigma álgebra} ($\\sigma$-álgebra) de subconjuntos de $\\Omega$ si las siguientes propiedades se cumplen:\n",
    "\n",
    "\\begin{enumerate}\n",
    "\\item Si $A \\in \\mathcal{F}$, entonces $A^{c} \\in \\mathcal{F}$.\n",
    "\n",
    "\\item Si $A_n \\in \\mathcal{F}$, $n = 1,2, \\ldots$, entonces $\\cup_{n=1}^{\\infty}A_n \\in \\mathcal{F}$ y $\\cap_{n=1}^{\\infty}A_n \\in \\mathcal{F}$.\n",
    "\\end{enumerate}\n",
    "\n",
    "\\end{definicion}\n",
    "\n",
    "De acuerdo a la definición \\ref{definicion:sigma algebra}, podemos restringir nuestra atención únicamente a los eventos que pertenecen a una sigma álgebra.\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Demuestre que si $\\mathcal{F}$ es una sigma álgebra y $A_n, B_n$, $n=1,2,\\ldots$ son una sucesión de eventos de $\\mathcal{F}$, entonces el conjunto\n",
    "$$\n",
    "\\left(\\cap_{n = 1}^{\\infty} A_{n}^{c}  \\right) \\cup \\left(\\cup_{n = 1}^{\\infty} B_{n}^{c}  \\right)\n",
    "$$\n",
    "pertenece a $\\mathcal{F}$.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Demuestre que si $\\mathcal{F}$ satisface las propiedades de la definición \\ref{definicion:sigma algebra}, entonces $\\Omega \\in \\mathcal{F}$ y $\\emptyset \\in \\mathcal{F}$.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Demuestre que una sigma álgebra es cerrada bajo intersecciones y uniones finitas.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\subsection{Medidas de probabilidad}\n",
    "\\label{seccion:medidas de probabilidad}\n",
    "%Definición de probabilidad frecuentista (ML a Bayesian pag 11)\n",
    "%Definición de medida de probabilidad (Hoel pag 8)\n",
    "%Propiedades de una medida de probabildiad (Hoel 10)\n",
    "%Fórmula de inclusión y exclusión (prob for ML pag 4)\n",
    "A continuación se enuncian dos definiciones de  probabilidad, la primera de ellas se basa fuertemente en la intuición frecuentista, mientras que la segunda está basada en la definición axiomática propuesta por Andrey Kolmogorov (1933)\n",
    "\n",
    "\\begin{definicion}[Probabilidad versión frecuentista]\n",
    "\\label{definicion:probabilidad frecuentista}\n",
    "Sea $\\Omega$ un espacio muestral y $\\mathcal{F}$ una $\\sigma$-álgebra de subconjuntos de $\\Omega$. La probabilidad de un evento $A \\in \\mathcal{F}$, está dada por el límite\n",
    "$$\n",
    "\\mathbb{P}(A) = \\lim_{n \\rightarrow \\infty} \\dfrac{n_A}{n}\n",
    "$$\n",
    "en donde $n$ es el número total de ensayos y $n_A$ es el número de veces que ocurre el evento $A$.\n",
    "\\end{definicion}\n",
    "En la práctica, la definición \\ref{definicion:probabilidad frecuentista} se encuentra limitada debido al hecho de que en la realidad $n$ y $n_A$ son números finitos y por lo tanto, lo que realmente se tiene es la aproximación\n",
    "$$\n",
    "\\mathbb{P}(A) \\approx \\lim_{n \\rightarrow \\infty} \\dfrac{n_A}{n}\n",
    "$$\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Utilizando la definición \\ref{definicion:probabilidad frecuentista}, ¿qué implicaría la probabilidad del evento \\textit{La empresa $X$ cae en incumplimiento}, si la empresa $X$ es relativamente joven?\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{definicion}[Probabilidad versión axiomática]\n",
    "Una medida de probabilidad $\\mathbb{P}$, definida sobre elementos de una $\\sigma$-álgebra $\\mathcal{F}$ de subconjuntos de un conjunto $\\Omega$, es una función $\\mathbb{P}:\\mathcal{F} \\rightarrow [0,1]$ que cumple lo siguiente:\n",
    "\n",
    "\\begin{enumerate}\n",
    "\\item $\\mathbb{P}(\\Omega) = 1$.\n",
    "\\item $\\mathbb{P}(A) \\geq 0$ para todo $A \\in \\mathcal{F}$.\n",
    "\\item Si $A_n$, $n=1,2,\\ldots$ son eventos mutuamente excluyentes (es decir, se tiene que  $A_i \\cap A_j = \\emptyset$ para $i \\neq j$), entonces \n",
    "$$\n",
    "\\mathbb{P}\\left(\\cup_{n=1}^{\\infty}A_n \\right) = \\sum_{n=1}^{\\infty}\\mathbb{P}(A_n)\n",
    "$$\n",
    "\\end{enumerate}\n",
    "\\end{definicion}\n",
    "\n",
    "\\begin{definicion}[Espacio de probabilidad]\n",
    "\\label{definicion:espacio de probabilidad}\n",
    "Un \\textbf{espacio de probabilidad} es una $3$-tupla $\\left( \\Omega, \\mathcal{F}, \\mathbb{P} \\right)$ en donde $\\Omega$ es un conjunto, $\\mathcal{F}$ es una sigma álgebra de subconjuntos de $\\Omega$ y $\\mathbb{P}$ es una medida de probabilidad definida sobre $\\mathcal{F}$.\n",
    "\\end{definicion}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Sea $(\\Omega, \\mathcal{F}, \\mathbb{P})$ un espacio de probabilidad tal que $\\mathbb{P}$ asigna a cada punto de $\\Omega$ una misma probabilidad $p > 0$.\n",
    "\\begin{enumerate}[label=\\alph*)]\n",
    "\\item Demuestre que $\\Omega$ tiene un número finito de puntos.\\\\ \\textbf{sugerencia:} Demuestre que $\\Omega$ no puede tener más de $p^{-1}$ puntos.\n",
    "\n",
    "\\item Demuestre que si $|\\Omega| = n$, entonces $p = \\dfrac{1}{n}$.\n",
    "\\end{enumerate}\n",
    "\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\subsubsection{Propiedades de las medidas de probabilidad}\n",
    "\n",
    "\\begin{teorema}\n",
    "\\label{teorema:propiedades de las medidas de probabilidad}\n",
    "Sea $\\left( \\Omega, \\mathcal{F}, \\mathbb{P} \\right)$ un espacio de probabilidad. La medida $\\mathbb{P}$ tiene las siguientes propiedades:\n",
    "\n",
    "\\begin{enumerate}\n",
    "\\item Para cualesquiera eventos $A,B$, $\\mathbb{P}(B) = \\mathbb{P}(A \\cap B) + \\mathbb{P}(A^c \\cap B)$ (demostrar, sugerencia $\\Omega = A \\cup A^c$).\n",
    "\n",
    "\\item $\\mathbb{P}(A^c) = 1 - \\mathbb{P}(A)$, en particular $\\mathbb{P}(\\emptyset) = 1 - \\mathbb{P}(\\Omega)$ (demostrar, sugerencia utilizar el punto anterior).\n",
    "\n",
    "\\item Si $A \\subset B$, entonces $\\mathbb{P}(B) \\geq \\mathbb{P}(A)$ (demostrar).\n",
    "\n",
    "\\item Sean $A_1, A_2, \\ldots, A_n$  eventos, entonces \n",
    "\\begin{align*}\n",
    "\\mathbb{P}(\\cup_{i=1}^{n}A_i)  = & \\sum_{i=1}^{n}\\mathbb{P}(A_i) - \\sum_{1 \\leq i < j \\leq n} \\mathbb{P}(A_i \\cap A_j) \\\\\n",
    "+ & \\sum_{1 \\leq i < j < k \\leq n} \\mathbb{P}(A_i \\cap A_j \\cap A_k) \\\\\n",
    "- & \\ldots + (-1)^{n + 1}\\mathbb{P}(A_1 \\cap A_2 \\cap \\ldots \\cap A_n)\n",
    "\\end{align*}\n",
    "\n",
    "como consecuencia\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(A \\cup B) \\leq \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\n",
    "$$\n",
    "\n",
    "\\end{enumerate}\n",
    "\n",
    "\\end{teorema}\n",
    "\n",
    "\\subsection{Probabilidad condicional e independencia}\n",
    "\\label{seccion:probabilidad condicional e independencia}\n",
    "%Definición de probabilidad condicional\n",
    "%teorema 1.4 (prob for ML pag 5)\n",
    "%Eventos mutuamente independientes (caso dos eventos y general Hoel pag 19)\n",
    "%Ejemplo 4 pág 15 Hoel, solución analítica y solución de simulación\n",
    "%Ejemplo 8 Hoel pag 20\n",
    "%Ejercicio 12 Hoel pag 23\n",
    "La definición de probabilidad condicional es fácil de motivar utilizando la intuición frecuentista. Supongamos que un experimento es repetido $n$ veces. Si $N_n(A), N_n(B), N_n(A \\cap B)$ denotan, respectivamente, el número de veces que ocurrieron los eventos $A, B, A \\cap B$, entonces para $n$ lo suficientemente grande $N_n(A)/n, N_n(B)/n, N_n(A \\cap B)/n$ aproximan $\\mathbb{P}(A), \\mathbb{P}(B), \\mathbb{P}(A \\cap B)$ respectivamente. Dentro de los $N_n(A)$ experimentos en los que el evento $A$ ocurre, el evento $B$ ocurre un número de $N_n(A \\cap B)$ veces. Por lo tanto la proporción de veces que ocurre el evento $B$ dado que $A$ también ha ocurrido, está dada por\n",
    "$$\n",
    "\\dfrac{N_n(A \\cap B)}{N_n(A)} = \\dfrac{N_n(A \\cap B) / n}{N_n(A) / n}\n",
    "$$\n",
    "y para $n$ lo suficientemente grande\n",
    "$$\n",
    "\\dfrac{N_n(A \\cap B)}{N_n(A)} \\approx \\dfrac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(A)}\n",
    "$$\n",
    "\\begin{definicion}[Probabilidad condicional]\n",
    "\\label{definicion:probabilidad condicional}\n",
    "Sean $A,B$ dos eventos tales que $\\mathbb{P}(A) > 0$. La probabilidad condicional de $B$ dado el evento $A$, se define como\n",
    "$$\n",
    "\\mathbb{P}(B | A) = \\dfrac{\\mathbb{P}(B \\cap A) }{\\mathbb{P}(A)}\n",
    "$$\n",
    "\\end{definicion}\n",
    "Las probabilidades condicionales pueden interpretarse como una actualización del espacio muestral $\\Omega$ debido al arribo de nueva información.\n",
    "\n",
    "\\begin{ejemplo}\n",
    "Supongamos que tenemos una caja con $r$ esferas rojas etiquetadas $1,2,\\ldots,r$ y $b$ esferas negras etiquetadas $1,2,\\ldots,b$. Supongamos que las esferas son equiprobables. Si elegimos una esfera de la caja y sabemos que es de color rojo, ¿cuál es la probabilidad de que tenga la etiqueta $1$?\n",
    "\\\\ \\textbf{Solución:}\\\\\n",
    "Dado que sabemos que la bola es roja, nuestra espacio muestral original $\\Omega$ se reduce al nuevo espacio $\\Omega{'}$, el cual está compuesto únicamente por las $r$ bolas rojas. Ya que estas bolas son equiprobables, se tiene que la probabilidad de tener la etiqueta $1$ es $\\tfrac{1}{r}$.\n",
    "\\end{ejemplo}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Resuelva el ejemplo anterior utilizando la definición \\ref{definicion:probabilidad condicional}.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Supongamos que la población de una ciudad está compuesta por $40\\%$ hombres y $60\\%$ mujeres. Supongamos también que $50\\%$ de los hombres y $30\\%$ de las mujeres fuman. Encuentre la probabilidad de que un fumador sea hombre.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{teorema}[Propiedades de la probabilidad condicional]\n",
    "\\label{teorema:propiedades probabilidad condicional}\n",
    "La probabilidad condicional cumple las siguientes propiedades:\n",
    "\\begin{enumerate}[label=\\alph*)]\n",
    "\\item (\\textbf{Fórmula de la probabilidad total}) Si $A_1, \\ldots, A_k$ forman una partición del espacio muestral $\\Omega$, es decir, $A_i \\cap A_j = \\emptyset$ para $i \\neq j$ y $\\cup_{i=1}^{k}A_i = \\Omega$ y si $0 < \\mathbb{P}(A_i) < 1$ para toda $i$, entonces para todo evento $B$\n",
    "$$\n",
    "\\mathbb{P}(B) = \\sum_{i=1}^{k}\\mathbb{P}(B|A_i)\\mathbb{P}(A_i)\n",
    "$$\n",
    "Utilizando este resultado, puede obtenerse la \\textbf{fórmula de Bayes}\n",
    "$$\n",
    "\\mathbb{P}(A_i|B) = \\dfrac{\\mathbb{P}(A_i) \\mathbb{P}(B|A_i) }{\\sum_{j=1}^{k} \\mathbb{P}(A_j) \\mathbb{P}(B|A_j)}\n",
    "$$\n",
    "\n",
    "Puede obtenerse también lo siguiente:\n",
    "$$\n",
    "\\mathbb{P}(B) = \\mathbb{P}(B|A)\\mathbb{P}(A) + \\mathbb{P}(B|A^c)\\mathbb{P}(A^c)\n",
    "$$\n",
    "\n",
    "\\item Sean $A_1, \\ldots, A_k$ eventos cualesquiera, entonces\n",
    "\\begin{align*}\n",
    "\\mathbb{P}(A_1 \\cap A_2 \\cap \\ldots \\cap A_k)  = & \\mathbb{P}(A_1)\\mathbb{P}(A_2|A_1)\\mathbb{P}(A_3|A_1 \\cap A_2)\\ldots \\\\\n",
    " \\times & \\mathbb{P}(A_k|A_1 \\cap A_2 \\cap \\ldots \\cap A_{k-1})\n",
    "\\end{align*}\n",
    "\\end{enumerate}\n",
    "\\end{teorema}\n",
    "\\begin{ejercicio}\n",
    "Demuestre el teorema \\ref{teorema:propiedades probabilidad condicional}.\n",
    "\\end{ejercicio}\n",
    "\\begin{ejercicio}\n",
    "Supongamos que tenemos una moneda $A$ que cae en cara con probabilidad $s$ y una moneda $B$ que cae en cara con probabilidad $t$. Si cada moneda se tira de manera alternada, empezando con la moneda $A$, ¿cuál es la probilidad de que la primera cara se obtenga con la moneda $A$?\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{definicion}[Independencia de eventos]\n",
    "\\label{definicion:independencia de eventos}\n",
    "Una colección de eventos $A_1, \\ldots, A_n$ se dice que es \\textbf{mutuamente independiente} si para cada $k, 1 \\leq k \\leq n$, y cualesquiera $k$ eventos, $A_{i_1}, \\ldots A_{i_k}$, se tiene que $\\mathbb{P}(A_{i_1} \\cap \\ldots A_{i_k}) = \\mathbb{P}(A_{i_1}) \\times \\ldots \\times \\mathbb{P}(A_{i_k})$.\n",
    "En particular, dos eventos son independientes si\n",
    "$$\n",
    "\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\mathbb{P}(B)\n",
    "$$ \n",
    "\\end{definicion}\n",
    "Utilizando la probabilidad condicional, para dos eventos independientes tenemos que\n",
    "$$\n",
    "\\mathbb{P}(B|A) = \\dfrac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(A)} = \\mathbb{P}(B)\n",
    "$$\n",
    "es decir, la ocurrencia del evento $A$ no afecta el resultado del evento $B$.\n",
    "\n",
    "\\chapter{Variables aleatorias}\n",
    "\\label{capitulo:variables aleatorias}\n",
    "%Definición formal de una variable aleatoria\n",
    "%Definición de una función de densidad\n",
    "%Definición de una función de distribución\n",
    "%Ejemplos de distribuciones\n",
    "%Funciones de una variable aleatoria\n",
    "%Independencia entre variables aleatorias\n",
    "%Momentos de una variable aleatoria\n",
    "%Fórmula de cambio de variable \n",
    "%Desigualdades famosas (prob for ML pag 19)\n",
    "%Fórmula del jacobiano\n",
    "%Funciones generadoras\n",
    "%Distribuciones relacionadas a la distribución normal\n",
    "%Ley de los grandes número y teorema del límite central\n",
    "%Distribuciones multivariadas\n",
    "%Distribuciones condicionales\n",
    "%Ejemplo curse of dimensionality (prob for ML pag 131)\n",
    "%Ejercicio esperanza condicional minimiza error cuadrático medio\n",
    "\n",
    "Recordemos que el espacio muestral $\\Omega$, contiene todos los resultados posibles de un experimento. Para cada uno de estos posibles resultados, $\\omega$, una variable aleatoria asigna un valor (generalmente numérico), es decir, una variable aleatoria, $X$, es realmente una función $X: \\Omega \\rightarrow \\mathbb{R}$, o $X: \\Omega \\rightarrow \\mathbb{R}^n$.\n",
    "\n",
    "La definición formal (es decir, desde el punto de vista de la teoría de la medida) de una variable aleatoria está dada por\n",
    "\n",
    "\\begin{definicion}[Variable aleatoria caso real]\n",
    "\\label{definicion: variable aleatoria caso real}\n",
    "Dado un espacio de probabilidad $(\\Omega, \\mathcal{F}, \\mathbb{P})$, una \\textbf{variable aleatoria} es una función $X$ de $\\Omega$ a los números reales $\\mathbb{R}$ tal que\n",
    "$$\n",
    "X(]\\infty, x])^{-1} = \\{\\omega  \\in \\Omega: X(\\omega) \\leq x  \\} \\in \\mathcal{F}, \\medspace \\mbox{para todo } x \\in \\mathbb{R}\n",
    "$$\n",
    "\\end{definicion}\n",
    "\\begin{nota}\n",
    "\\label{nota: notacion probabilidades}\n",
    "Se utilizará la siguiente notación\n",
    "$$\n",
    "\\mathbb{P}[X(]\\infty, x])^{-1}] :=\\mathbb{P}[X \\leq x]\n",
    "$$\n",
    "de manera similar para los otros eventos.\n",
    "\\end{nota}\n",
    "\n",
    "\\section{Caso discreto}\n",
    "\\label{seccion:variables discretas}\n",
    "\\begin{definicion}[Variable aleatoria discreta, caso real]\n",
    "Una variable aleatoria \\textbf{discreta} con valores sobre el conjunto $\\mathbb{R}$, es una función de $\\Omega$ sobre un subconjunto finito o numerable infinito $\\{x_1, x_2, \\ldots\\}$ de números reales, de tal manera que $\\{\\omega: X(\\omega) = x_i \\} \\in \\mathcal{F}$ para toda $i$.\n",
    "\\end{definicion}\n",
    "Cada variable aleatoria discreta, $X$, tiene asociada una función, $f$, llamada la \\textbf{función de densidad} (o función de masa).\n",
    "\n",
    "\\begin{definicion}[Función de densidad, caso discreto]\n",
    "\\label{definicion:funcion de densidad, caso discreto}\n",
    "Sea $X$ una variable aleatoria discreta con valores en $\\mathbb{R}$. Si $f$ es una función tal que:\n",
    "\\begin{enumerate}[label=\\alph*)]\n",
    "\\item $f(x) = \\mathbb{P}(X = x) \\geq 0$ para todo $x \\in \\mathbb{R}$.\n",
    "\\item El conjunto $A = \\{x: f(x) \\neq 0 \\}$ es un subconjunto finito o numerable infinito de $\\mathbb{R}$.\n",
    "\\item $\\sum_{x \\in A} f(x) = 1$.\n",
    "\\end{enumerate}\n",
    "entonces decimos que $f$ es una función de densidad (o función de masa) de $X$.\n",
    "\\end{definicion}\n",
    "\n",
    "Es posible asignar una variable aleatoria a cada función que satisface las condiciones de la definición \\ref{definicion:funcion de densidad, caso discreto}. Es decir, podemos construir un espacio de probabilidad $(\\Omega, \\mathcal{F}, \\mathbb{P})$ y una variable $X$ definida sobre $\\Omega$ cuya densidad sea $f$. Sea $\\{x_1, x_2, \\ldots \\}$ el conjunto de valores para los cuales $f(x) \\neq 0$. Definamos $\\Omega = \\{x_1, x_2, \\ldots \\}$, $\\mathcal{F} = \\mathcal{P}(\\Omega)$ (el conjunto potencia de $\\Omega$) y $\\mathbb{P}$ la medida de probabilidad definida sobre $\\mathcal{F}$ como $\\mathbb{P}( \\{\\omega \\} ) = f(x_i)$ si $\\omega = x_i$. Si definimos $X$ como $X(\\omega) = x_i$ si $\\omega = x_i$, entonces\n",
    "$$\n",
    "\\mathbb{P}(X = x_i) = \\mathbb{P}(\\{\\omega: X(\\omega) = x_i \\}) = \\mathbb{P}(\\{x_i\\}) = f(x_i)\n",
    "$$\n",
    "\n",
    "Sea $A \\subseteq \\mathbb{R}$ y sea $X$ una variable aleatoria discreta con posibles valores $x_1, x_2, \\ldots$. Entonces el conjunto $\\{\\omega: X(\\omega) \\in A  \\}$ es un evento, esto se debe a que\n",
    "$$\n",
    "\\{\\omega: X(\\omega) \\in A  \\} = \\bigcup_{x_i \\in A} \\{\\omega: X(\\omega) = x_i \\}\n",
    "$$\n",
    "\\begin{nota}\n",
    "Es común utilizar la siguiente notación\n",
    "$$\n",
    "\\{\\omega: X(\\omega) \\in A  \\} = \\{X \\in A\\}\n",
    "$$\n",
    "\\end{nota}\n",
    "Podemos calcular $\\mathbb{P}(X \\in A)$ utilizando la siguiente fórmula\n",
    "$$\n",
    "\\mathbb{P}(X \\in A) = \\sum_{x_i \\in A}f(x_i)\n",
    "$$\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Demuestre que \n",
    "$$\n",
    "\\mathbb{P}(X \\in A) = \\sum_{x_i \\in A}f(x_i)\n",
    "$$\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{definicion}[Función de distribución acumulativa, caso discreto]\n",
    "\\label{definicion:funcion de distribucion caso discreto}\n",
    "La función $F(t), -\\infty < t < \\infty$ definida por\n",
    "$$\n",
    "F(t) = \\mathbb{P}(X \\leq t) = \\sum_{x \\leq t} f(x)\n",
    "$$\n",
    "recibe el nombre de \\textbf{función de distribución acumulativa} (o simplemente función de distribución) de la variable aleatoria discreta $X$.\n",
    "\\end{definicion}\n",
    "\n",
    "\\begin{teorema}[Propiedades de la función de distribución]\n",
    "\\label{teorema: propiedades de la funcion de distribucion}\n",
    "Sea $X:\\Omega \\rightarrow \\mathbb{R}$, una variable aleatoria. Una función $F(x)$ es la función de distribución de $X$ si y sólo si satisface las siguientes condiciones:\n",
    "\\begin{enumerate}[label=\\alph*)]\n",
    "\\item Para toda $x \\in \\mathbb{R}$, $0 \\leq F(x) \\leq 1$.\n",
    "\\item $F(x) \\rightarrow 0$ cuando $x \\rightarrow -\\infty$, y  $F(x) \\rightarrow 1$ cuando $x \\rightarrow \\infty$.\n",
    "\\item Dado un número real $a$, $F(x) \\downarrow F(a)$ cuando $x \\downarrow a$ (continuidad por la derecha).\n",
    "\\item Para cualesquiera dos números reales $x < y$, $F(x) \\leq F(y)$.\n",
    "\\end{enumerate}\n",
    "\\end{teorema}\n",
    "\\begin{nota}\n",
    "El teorema \\ref{teorema: propiedades de la funcion de distribucion}, es válido para cualquier tipo de variables con valores en los reales (discretas, continuas o mixtas).\n",
    "\\end{nota}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "%Hoel pág 110\n",
    "Demuestre que para cualesquiera numeros $a \\leq b$\n",
    "$$\n",
    "\\mathbb{P}(a < X \\leq b) = F(b) - F(a)\n",
    "$$\n",
    "\\textbf{Sugerencia:} Considere los conjuntos $A = \\{ \\omega: X(\\omega) \\leq a\\}, B = \\{\\omega: X(\\omega) \\leq b\\}$ y recuerde que para todo conjunto $A$\n",
    "$$\\mathbb{P}(A) = \\mathbb{P}(A \\cap B) + \\mathbb{P}(A \\cap B^c).$$\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{ejemplo}\n",
    "Considere un juego de baraja inglesa. Si $X$ denota el número de ases en una mano, encuentre la función de densidad y la función de distribución de $X$.\\\\\n",
    "\\textbf{Solución:}\\\\\n",
    "Utilizando argumentos de cálculo combinatorio tenemos que:\n",
    "$$\n",
    "\\mathbb{P}(X = x) = \\dfrac{\\begin{pmatrix} 4 \\\\ x\n",
    "\\end{pmatrix} \\begin{pmatrix} 48 \\\\ 13 - x \\end{pmatrix}} { \\begin{pmatrix} 52 \\\\ 13\\end{pmatrix} }\n",
    "$$\n",
    "para $x =0,1,2,3,4$.\n",
    "Utilizando la función de densidad, podemos calcular la función de distribución acumulativa de la siguiente manera:\n",
    "$$\n",
    "\\begin{array}{lcr}\n",
    "F(x) & = & 0 \\medspace \\mbox{ Si } x < 0.\\\\\n",
    " & = & f(0) \\medspace \\mbox{ Si } 0\\leq x < 1\\\\\n",
    " & = & f(0) + f(1) \\medspace \\mbox{ Si } 1\\leq x < 2\\\\\n",
    " & = & f(0) + f(1) + f(2) \\medspace \\mbox{ Si } 2\\leq x < 3\\\\\n",
    " & = & f(0) + f(1) + f(2) + f(3) \\medspace \\mbox{ Si } 3\\leq x < 4\\\\\n",
    " & = & 1 \\medspace \\mbox{ Si } x \\geq 4.\n",
    "\\end{array}\n",
    "$$\n",
    "\\end{ejemplo}\n",
    "\n",
    "\\begin{proposicion}[Función de una variable aleatoria]\n",
    "\\label{proposicion:funcion de una variable aleatoria}\n",
    "Sea $X$ una variable aleatoria discreta y sea $Y = g(X)$. Entonces\n",
    "$$\n",
    "\\mathbb{P}(Y = y) = \\sum_{x: g(x) = y} \\mathbb{P}(X = x)\n",
    "$$\n",
    "\\end{proposicion}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Si $X$ tiene función de densidad\n",
    "$$\n",
    "f(x) = \\dfrac{c}{1 + x^2}\n",
    "$$\n",
    "para $x = 0, \\pm 1, \\pm 2, \\pm 3$. Encuentre el valor de $c$ y la función de densidad de\n",
    "$$\n",
    "Y = sen\\left( \\dfrac{\\pi}{2}X \\right)\n",
    "$$\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\subsection{Esperanza y momentos}\n",
    "El concepto de esperanza de una variable aleatoria está relacionado con la idea de promediar los posibles valores que la variable puede tomar. En lugar de utilizar un promedio común, en donde a cada posible valor se le da la misma ponderación, las ponderaciones son asignadas a través de la función de densidad de la variable.\n",
    "\n",
    "\\begin{definicion}[Esperanza, caso discreto]\n",
    "\\label{definicion:esperanza caso discreto}\n",
    "Sea $X$ una variable aleatoria discreta. Si $\\sum_{i} |x_i|f(x_i) < \\infty$, definimos la esperanza (media) de $X$ como\n",
    "$$\n",
    "\\mu = E[X] = \\sum_{i}x_if(x_i)\n",
    "$$\n",
    "\\end{definicion}\n",
    "\n",
    "\\begin{teorema}[Propiedades de la esperanza]\n",
    "\\label{teorema:propiedades de la esperanza}\n",
    "La esperanza cumple lo siguiente:\n",
    "\\begin{enumerate}[label=\\alph*)]\n",
    "\\item Si $\\mathbb{P}(X = c) = 1$ para una constante $c$, entonces $E[X] = c$.\n",
    "\\item Si $X,Y$ son variables aleatorias definidas sobre el mismo espacio $\\Omega$, ambas con esperanza finita y si $\\mathbb{P}(X \\leq Y) = 1$, entonces $E[X] \\leq E[Y]$.\n",
    "\\item Si $X$ tiene esperanza finita y si $\\mathbb{P}(X \\geq c) = 1$, entonces $E[X] \\geq c$. De la misma forma, si $\\mathbb{P}(X \\leq c) = 1$, entonces $E[X] \\leq c$.\n",
    "\\item $|E[X]| \\leq E[|X|]$.\n",
    "\\item Si $Y = g(X)$, entonces $E[Y] = \\sum_{i}g(x_i)f(x_i)$.\n",
    "\\item Si $X_1, X_2, \\ldots, X_n$ son variables aleatorias definidas sobre el mismo espacio $\\Omega$, con esperanza finita y si $c_1, \\ldots, c_n$ son constantes, entonces\n",
    "$$\n",
    "E\\left[ \\sum_{i=1}^{n}c_{i}X_i \\right] = \\sum_{i=1}^{n}c_iE[X_i]\n",
    "$$\n",
    "\\end{enumerate}\n",
    "\\end{teorema}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Demuestre que si $X$ es una variable aleatoria que toma los valores $0,1,2,\\ldots$ y con esperanza finita, entonces\n",
    "$$\n",
    "E[X] = \\sum_{n=0}^{\\infty} \\mathbb{P}(X > n)\n",
    "$$\n",
    "\\end{ejercicio}\n",
    "La esperanza se calcula con la intención de entender el valor típico de la variable aleatoria. Sin embargo, esta cantidad no nos dice nada sobre la variabilidad de los mismos. Una de las medidas más utilizadas para cuantificar esta variabilidad es la varianza, la cual se define a continuación.\n",
    "\n",
    "\\begin{definicion}[Varianza de una variable aleatoria]\n",
    "Sea $X$ una variable con media finita. La varianza de $X$ se define como\n",
    "$$\n",
    "\\sigma^2 = Var[X] =  E[(X - \\mu)^2]\n",
    "$$\n",
    "La desviación estándar de $X$ se define como $\\sigma = \\sqrt{\\sigma^2}$.\n",
    "\\end{definicion}\n",
    "\n",
    "\\begin{proposicion}[Propiedades de la varianza]\n",
    "\\label{proposicion:propiedades de la varianza}\n",
    "La varianza cumple lo siguiente:\n",
    "\\begin{enumerate}[label=\\alph*)]\n",
    "\\item Para toda constante $c \\in \\mathbb{R}$, $Var(cX) = c^2Var(X)$.\n",
    "\\item Para toda constante $c \\in \\mathbb{R}$, $Var(X + c) = Var(X)$.\n",
    "\\item $Var(X) \\geq 0$, para toda variable aleatoria $X$. La igualdad se cumple sólo si $\\mathbb{P}(X = c)=1$ para algún número $c$ constante.\n",
    "\\item $Var(X) = E(X^2) - (E[X])^2$.\n",
    "\\end{enumerate}\n",
    "\\end{proposicion}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Demuestre la proposición \\ref{proposicion:propiedades de la varianza}.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{definicion}[K-ésimo momento]\n",
    "Sea $X$ una variable aleatoria y $k \\geq 1$ un entero. El k-ésimo momento de $X$ está dado por $E[X^k]$.\n",
    "\\end{definicion}\n",
    "\n",
    "\\begin{definicion}[Sesgo y curtosis]\n",
    "\\label{definicion:sesgo y curtosis}\n",
    "Sea $X$ una variable aleatoria con $E[|X|^3]<\\infty$. El sesgo de $X$ se define como\n",
    "$$\n",
    "\\dfrac{E[(X- \\mu)^3]}{\\sigma^3}.\n",
    "$$\n",
    "Supongamos que $E[X^4] < \\infty$. La curtosis de $X$ está dada por\n",
    "$$\n",
    "\\dfrac{E[(X - \\mu)^4]}{\\sigma^4} - 3.\n",
    "$$\n",
    "\\end{definicion}\n",
    "El sesgo es utilizado como una medida de asimetría en la distribución de los valores de la variable aleatoria. Si la variable $X$ tiene una distribución simétrica, entonces todos los momentos impares alrededor de la media, $E[(X - \\mu)^{2k + 1}]$ serán iguales a cero, en particular, el sesgo será igual a cero.\n",
    "\n",
    "Por otro lado, la curtosis de una variable nos indica que tan concentrada (puntiaguda por así decirlo) es la distribución de los valores alrededor de la media.\n",
    "\n",
    "\n",
    "\\subsection{Distribuciones discretas más comúnes}\n",
    "\\label{seccion: distribuciones discretas}\n",
    "\\begin{enumerate}[label=\\alph*)]\n",
    "\\item \\textbf{Binomial:} $Bin(n,p)$\n",
    "$$\n",
    "\\mathbb{P}(X=x) = \\begin{pmatrix}\n",
    "n \\\\\n",
    "x\n",
    "\\end{pmatrix} p^{x}(1 - p)^{n -x} \\qquad x=0,1,\\ldots,n.\n",
    "$$\n",
    "$$\n",
    "\\begin{matrix}\n",
    "E[X] = np & Var(X) = np(1-p) \\\\\n",
    "E[(X - \\mu)^3] = np(1-3p+2p^2) & E[(X - \\mu)^4] = np(1-p)[1 + 3(n-2)p(1-p)]\n",
    "\\end{matrix}\n",
    "$$\n",
    "\\item \\textbf{Geométrica:} $Geom(p)$\n",
    "$$\n",
    "\\mathbb{P}(X = x) = p(1-p)^{x-1} \\qquad x=1,2,3,\\ldots.\n",
    "$$\n",
    "$$\n",
    "\\begin{matrix}\n",
    "E[X] = \\dfrac{1}{p} & Var(X) = \\dfrac{1-p}{p^2} \\\\\n",
    "\\end{matrix}\n",
    "$$\n",
    "\\item \\textbf{Binomial negativa:} $NegBin(r,p)$\n",
    "$$\n",
    "\\mathbb{P}(X=x) = \\begin{pmatrix}\n",
    "x-1 \\\\\n",
    "r-1\n",
    "\\end{pmatrix} p^{r}(1-p)^{x-r}, \\qquad x=r,r+1,\\ldots.\n",
    "$$\n",
    "$$\n",
    "\\begin{matrix}\n",
    "E[X] = \\dfrac{r}{p} & Var(X) = \\dfrac{r(1-p)}{p^2}.\n",
    "\\end{matrix}\n",
    "$$\n",
    "\\item \\textbf{Hipergeométrica:} $Hiper(n,D,N)$\n",
    "$$\n",
    "\\mathbb{P}(X = x) = \\dfrac{ \\begin{pmatrix}\n",
    "D \\\\\n",
    "x\n",
    "\\end{pmatrix} \\begin{pmatrix}\n",
    "N-D \\\\\n",
    "n-x\n",
    "\\end{pmatrix} }{ \\begin{pmatrix}\n",
    "N \\\\\n",
    "n\n",
    "\\end{pmatrix}}, \\qquad n-N+D \\leq x \\leq D.\n",
    "$$\n",
    "$$\n",
    "\\begin{matrix}\n",
    "E[X] = np & Var(X) = np(1-p)\\left( \\dfrac{N-n}{N-1} \\right)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\\item \\textbf{Poisson:}$Poi(\\lambda)$\n",
    "$$\n",
    "\\mathbb{P}(X = x) = \\dfrac{e^{-\\lambda} \\lambda^x }{x!} \\qquad x=0,1,2,\\ldots. \n",
    "$$\n",
    "$$\n",
    "\\begin{matrix}\n",
    "E[X] = \\lambda & Var(X) = \\lambda \\\\\n",
    "E[(X-\\lambda)^3] = \\lambda & E[(X - \\lambda)^4] = 3\\lambda^2 + \\lambda\n",
    "\\end{matrix}\n",
    "$$\n",
    "\\end{enumerate}\n",
    "\\section{Caso continuo}\n",
    "\\label{seccion:variables continuas}\n",
    "Una variable aleatoria continua, toma valores en subintervalos o dentro de conjuntos generados por subintervalos de $\\mathbb{R}$. Algunos ejemplos de variables aleatorias continuas son:\n",
    "\\begin{itemize}\n",
    "\\item Precio de un instrumento financiero.\n",
    "\\item Tiempo para que una compañía caiga en incumplimiento de sus obligaciones contractuales.\n",
    "\\item Número de veces que una acción presenta ganancias en un intervalo de tiempo dado.\n",
    "\\item Rendimientos de un portafolio.\n",
    "\\end{itemize}\n",
    "\n",
    "\\begin{definicion}[Variable aleatoria, caso continuo]\n",
    "\\label{definicion: Variable aleatoria caso continuo}\n",
    "Una variable, $X$, sobre un espacio de probabilidad $(\\Omega, \\mathcal{F}, \\mathbb{P})$ es una función $X:\\Omega \\rightarrow \\mathbb{R}$ tal que para toda $x \\in \\mathbb{R}$ se tiene que\n",
    "$$\n",
    "\\{ \\omega \\in \\Omega: X(\\omega) \\leq x \\} \\in \\mathcal{F}\n",
    "$$\n",
    "es decir, el conjunto $\\{ \\omega \\in \\Omega: X(\\omega) \\leq x \\}$ es un evento.\n",
    "\\end{definicion}\n",
    "Al igual que en el caso discreto, la función de distribución de una variable aleatoria continua, es la función, $F$, tal que \n",
    "$$\n",
    "F(x) = \\mathbb{P}(X \\leq x)\n",
    "$$\n",
    "\\begin{ejercicio}\n",
    "%Hoel pag 110\n",
    "Considere el experimento de elegir un punto al azar dentro del disco de radio $R$ centrado en el origen. Sea $X$ la variable aleatoria que denota la distancia entre el punto elegido y el origen. Encuentre la función de distribución de $X$.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{teorema}\n",
    "Una variable aleatoria, $X$, es una variable aleatoria continua si y sólo si su función de distribución, $F$, es continua en todo punto $x$.\n",
    "\\end{teorema}\n",
    "Como consecuencia del teorema anterior, tenemos que para cualesquiera números $a \\leq b$.\n",
    "$$\n",
    "\\mathbb{P}(a < X < b) = \\mathbb{P}(a \\leq X \\leq b) = \\mathbb{P}(a \\leq X < b)\n",
    "$$\n",
    "\n",
    "\\begin{definicion}[Función de densidad, caso continuo]\n",
    "\\label{definicion:funcion de densidad caso continuo}\n",
    "Una funcióin de densidad (con respecto a la integración) es una función no negativa, $f\\geq 0$, tal que \n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} f(x)dx = 1\n",
    "$$\n",
    "Observemos que si $f$ es una función de densidad, entonces la función, $F$, definida por\n",
    "$$\n",
    "F(x) = \\int_{- \\infty}^{x} f(y)dy, \\qquad -\\infty < x < \\infty.\n",
    "$$\n",
    "es una función de distribución.\n",
    "\n",
    "No todas las funciones de distribución tienen asociadas una función de densidad, aquellas que sí la tienen son llamadas \\textbf{absolutamente continuas}.\n",
    "\\end{definicion}\n",
    "\n",
    "De lo anterior, se sigue que para una variable aleatoria continua $X$ con densidad $f$\n",
    "$$\n",
    "\\mathbb{P}(a \\leq X \\leq b) = \\int_{a}^{b}f(x)dx\n",
    "$$\n",
    "o de manera más general, si $A$ es la unión (numerable) de intervalos disjuntos\n",
    "$$\n",
    "\\mathbb{P}(X \\in A) = \\int_{A}f(x)dx.\n",
    "$$\n",
    "\n",
    "Finalmente, es importante señalar que si $F$ es absolutamente continua, la densidad $f$ no es única, ya que puede ser modificada en un conjunto finito de puntos (de manera más general, cualquier conjunto de medida cero) sin alterar el valor de la integral.\n",
    "\n",
    "\\begin{teorema}[Teorema de cambio de variable]\n",
    "\\label{teorema:cambio de variable}\n",
    "Sea $\\psi$ una función derivable, estrictamente creciente o decreciente sobre un intervalo $I$ y sea $\\psi(I)$ el rango de $\\psi$. Sea $X$ una función aleatoria continua $X$ con densidad $f$, tal que $f(x) = 0$ para $x \\notin I$. Entonces $Y = \\psi(X)$ tiene densidad $g$ dada por $g(y) = 0$ para $y \\notin \\psi(I)$ y \n",
    "$$\n",
    "g(y) = f(\\psi^{-1}(y)) \\left| \\dfrac{d}{dy}\\psi{-1}(y)\\right|, \\qquad y \\in \\psi(I).\n",
    "$$\n",
    "\\end{teorema}\n",
    "\n",
    "\\begin{demostracion}\n",
    "Sean $F$ y $G$ las funciones de distribución de $X$ y $Y$ respectivamente. Primero supongamos que $\\psi$ es estrictamente creciente, por lo tanto, $\\psi{-1}$ también es estrictamente creciente sobre $\\psi(I)$ y para $y \\in \\psi(I)$\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "G(y) & = & \\mathbb{P}(Y \\leq y)\\\\\n",
    " & = & \\mathbb{P}(\\psi(X) \\leq y) \\\\\n",
    " & = & \\mathbb{P}(X \\leq \\psi^{-1}(y))\\\\\n",
    " & = & F(\\psi^{-1}(y)).\n",
    "\\end{array}\n",
    "$$\n",
    "Derivando respecto a $y$, se obtiene\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "G^{'}(y) & = & \\dfrac{d}{dy}F(\\psi^{-1}(y))\\\\\n",
    "& = & F^{'}(\\psi^{-1}(y))\\dfrac{d}{dy}\\psi^{-1}(y)\\\\\n",
    "& = & f(\\psi{-1}(y))\\dfrac{d}{dy}\\psi{-1}(y).\n",
    "\\end{array}\n",
    "$$\n",
    "Y como\n",
    "$$\n",
    "\\dfrac{d}{dy}\\psi^{-1}(y) = \\left| \\dfrac{d}{dy}\\psi{-1}(y) \\right| \\qquad \\mbox{¿por qué?}\n",
    "$$\n",
    "se tiene que le ecuación se cumple.\n",
    "\n",
    "Ahora supongamos que $\\psi$ es estrictamente decreciente, por lo tanto también lo es $\\psi^{-1}$, para $y \\in \\psi(I)$ tenemos\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "G(y) & = & \\mathbb{P}(Y \\leq y) \\\\\n",
    "& = & \\mathbb{P}(\\psi(X) \\leq y) \\\\\n",
    "& = & \\mathbb{P}(X \\geq \\psi^{-1}(y)) \\qquad \\mbox{¿por qué?} \\\\\n",
    "& = & 1 - F(\\psi^{-1}(y)).\n",
    "\\end{array}\n",
    "$$\n",
    "Derivando respecto a $y$\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "G^{'}(y) & = & -F^{'}(\\psi{-1}(y))\\dfrac{d}{dy}\\psi{-1}(y)\\\\\n",
    "& = & f(\\psi^{-1}(y))\\left( - \\dfrac{d}{dy} \\psi^{-1}(y)  \\right) \\\\\n",
    " & = & f(\\psi^{-1}(y))\\left| \\dfrac{d}{dy} \\psi^{-1}(y)  \\right| \\qquad \\mbox{¿por qué?}. \n",
    "\\end{array}\n",
    "$$\n",
    "lo que finaliza la demostración $\\qed$.\n",
    "\\end{demostracion}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "%Hoel pág 117\n",
    "Sea $X$ una variable aleatoria continua con densidad $f$. Encuentre la densidad de $Y = X^2$.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\chapter{Variables aleatorias multivariadas}\n",
    "\\label{capitulo:variables aleatorias multivariadas}\n",
    "\\begin{definicion}[Covarianza y coeficiente de variación]\n",
    "\\label{definicion:covarianza}\n",
    "Sean $X,Y$ dos variables aleatorias con esperanza finita, la covarianza de $X$ y $Y$ está dada por\n",
    "$$\n",
    "Cov(X,Y) = E[(X - \\mu_{X})(Y - \\mu_{Y})]\n",
    "$$\n",
    "La covarianza busca medir el grado de dependencia (lineal) entre dos variables, sin embargo, al ser una cantidad no acotada y que depende de las unidades de las variables involucradas, su interpretación es difícil. Una forma de solucionar es a través del coeficiente de variación, el cual se define como\n",
    "$$\n",
    "\\rho(X,Y) = \\dfrac{ Cov(X,Y)  }{ \\sqrt{Var(X) Var(Y)} }.\n",
    "$$\n",
    "Utilizando la desigualdad de Schwarz es fácil ver que $-1\\leq \\rho(X,Y) \\leq 1$.\n",
    "\\end{definicion}\n",
    "\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Demuestre que $Cov(X,Y) = E[XY] - E[X]E[Y]$.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{definicion}[Variables independientes]\n",
    "Sean $X_1, X_2,\\ldots,X_k$ variables aleatorias definidas sobre el mismo espacio $\\Omega$. Decimos que las variables $X_1, X_2,\\ldots,X_k$ son independientes si\n",
    "$$\n",
    "\\mathbb{P}(X_1 = x1, X_2 = x_2, \\ldots, X_k = x_k) = \\mathbb{P}(X_1 = x_2)\\mathbb{P}(X_2 = x_2)\\ldots\\mathbb{P}(X_k = x_k).\n",
    "$$\n",
    "\\end{definicion}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Suponga que $X,Y$ son variables aleatorias independientes con funciones de densidad $f_x, f_y$ respectivamente. Demuestre que para cualesquiera subconjuntos $A,B \\in \\mathcal{F}$, se tiene que\n",
    "$$\n",
    "\\mathbb{P}(X \\in A, Y \\in B) = \\mathbb{P}(X \\in A)\\mathbb{P}(Y \\in B)\n",
    "$$\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Suponga que las variables $X_1, X_2, \\ldots, X_n$ son variables independientes con esperanza finita. Demuestre la igualdad\n",
    "$$\n",
    "E[\\Pi_{i=1}^{n}X_i] = \\Pi_{i=1}^{n}E[X_i].\n",
    "$$\n",
    "En particular, si $X,Y$ son independientes, $Cov(X,Y) = 0$.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Sean $X,Y$ variables aleatorias independientes.\n",
    "\\begin{enumerate}[label=\\alph*)]\n",
    "\\item Encuentre la distribución de $\\min(X,Y)$.\n",
    "\\item Encuentre la distribución de $\\max(X,Y)$.\n",
    "\\item Encuentre $\\mathbb{P}(\\min(X,Y) = X) = \\mathbb{P}(Y \\geq X)$.\n",
    "\\item Encuentre la distribución de $X + Y$.\n",
    "\\end{enumerate}\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Suponga que las variables $X_1, X_2, \\ldots, X_n$ son independientes. Demuestre\n",
    "$$\n",
    "Var(X_1 + X_2 + \\ldots + X_n) = \\sum_{i=1}^{n}Var(X_i).\n",
    "$$\n",
    "\\textbf{Sugerencia:} Demuestre primero el caso con dos variables.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\\begin{ejercicio}\n",
    "Sean $X_1, X_2, \\ldots, X_n$ variables independientes con varianza común $\\sigma^2 < \\infty$. Sea $\\bar{X} = \\dfrac{\\sum_{i=1}^{n} X_i }{n}$, demuestre que $Var(\\bar{X}) = \\dfrac{\\sigma^2}{n}$.\n",
    "\\end{ejercicio}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\end{document}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
