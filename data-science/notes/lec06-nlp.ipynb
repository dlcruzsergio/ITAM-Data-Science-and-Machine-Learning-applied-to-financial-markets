{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../files/misc/logo.png\" width=300/>\n",
    "<h1 style=\"color:#872325\"> Natural Language Processing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Natural Language**\n",
    "> _a language that has developed naturally in use (as contrasted with an artificial language or computer code)._\n",
    "\n",
    "---\n",
    "\n",
    "Existen dos principales razones por las cuáles estamos interesados en hacer programas de computación que entiendan lenguaje natural:\n",
    "1. Comunicación entre humanos\n",
    "2. Para obtener información de un lenguaje escrito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de desear obtener información, podemos dividir esta clase de problemas en tres sub-problemas:\n",
    "\n",
    "- Clasificación de Textos\n",
    "- Aquisición de información\n",
    "- Extracción de información\n",
    "\n",
    "Para resolver estas clases de problemas haremos uso de los **modelos de lenguaje** los cuales estiman distribuciones de probabilidad sobre expresiones del lenguaje\n",
    "\n",
    "* Definimos un modelo de lenguaje natural como una distribución de probabilidad sobre oraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras, _corpus_ y _corpora_\n",
    "\n",
    "**corpus**: a computer-readable collection of text or speech.  \n",
    "**corpora**: plural de corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completa la frase\n",
    "Ayer vi a mi..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El modelo $n$-gram\n",
    "\n",
    "La finalidad de un modelo $n$-gram es modelar una secuencia de $n$ elementos (palabras, en este caso) dada una muestra de texto. Para lograr esto, el modelo asume que la probabilidad del acontecimiento de una palabra, dada toda una historia de palabras que la preceden, es igual a la probabilidad de esa misma palabra dada las últimas $n$ palabras que se dijeron.\n",
    "\n",
    "Formalmente, un modelo $n$-gram se define como una Cadena de Markov de order $n-1$. Esto es,\n",
    "\n",
    "$$\n",
    "    \\mathbb P(W_m \\ | \\  W_{m-1}, W_{m-2}, \\ldots, W_{1}) = \\mathbb P(W_m \\ | \\ W_{m-1}, W_{m-2}, \\ldots, W_{m-n+1})\n",
    "$$\n",
    "\n",
    "\n",
    "Dado un texto (o corpus) con $m$ palabras o carácteres y $n \\leq m$,\n",
    "\n",
    "\n",
    "Dado esto, vemos que un $1$-gram (o *unigram* asume que)\n",
    "$$\n",
    "\\mathbb P(W_m \\ | \\  W_{m-1}, W_{m-2}, \\ldots, W_{1}) = \\mathbb P(X_m)\n",
    "$$\n",
    "\n",
    "un $2$-gram (o bigram), el cuál cumple la [propiedad de Markov](https://es.wikipedia.org/wiki/Cadena_de_Márkov), asume que,\n",
    "$$\n",
    "\\mathbb P(W_m \\ | \\  W_{m-1}, W_{m-2}, \\ldots, W_{1}) = \\mathbb P(X_m \\ | \\ X_{m-1})\n",
    "$$\n",
    "\n",
    "un $3$-gram,\n",
    "$$\n",
    "    \\mathbb P(W_m \\ | \\  W_{m-1}, W_{m-2}, \\ldots, W_{1}) = \\mathbb P(X_m \\ | \\ X_{m-1}, X_{m-2})\n",
    "$$\n",
    "\n",
    "y así sucesivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La construcción de elementos para un modelo $n$-gram puede ser hehca considerando carácter por carácter o palabra por palabra. A cada elemento le llamamos un **token**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('W', 'a', 'r')\n",
      "('a', 'r', ' ')\n",
      "('r', ' ', 'i')\n",
      "(' ', 'i', 's')\n",
      "('i', 's', ' ')\n",
      "('s', ' ', 'p')\n",
      "(' ', 'p', 'e')\n",
      "('p', 'e', 'a')\n",
      "('e', 'a', 'c')\n",
      "('a', 'c', 'e')\n",
      "('c', 'e', ' ')\n",
      "('e', ' ', 'f')\n",
      "(' ', 'f', 'r')\n",
      "('f', 'r', 'e')\n",
      "('r', 'e', 'e')\n",
      "('e', 'e', 'd')\n",
      "('e', 'd', 'o')\n",
      "('d', 'o', 'm')\n",
      "('o', 'm', ' ')\n",
      "('m', ' ', 'i')\n",
      "(' ', 'i', 's')\n",
      "('i', 's', ' ')\n",
      "('s', ' ', 's')\n",
      "(' ', 's', 'l')\n",
      "('s', 'l', 'a')\n",
      "('l', 'a', 'v')\n",
      "('a', 'v', 'e')\n",
      "('v', 'e', 'r')\n",
      "('e', 'r', 'y')\n",
      "('r', 'y', ' ')\n",
      "('y', ' ', 'i')\n",
      "(' ', 'i', 'g')\n",
      "('i', 'g', 'n')\n",
      "('g', 'n', 'o')\n",
      "('n', 'o', 'r')\n",
      "('o', 'r', 'a')\n",
      "('r', 'a', 'n')\n",
      "('a', 'n', 'c')\n",
      "('n', 'c', 'e')\n",
      "('c', 'e', ' ')\n",
      "('e', ' ', 'i')\n",
      "(' ', 'i', 's')\n",
      "('i', 's', ' ')\n",
      "('s', ' ', 's')\n",
      "(' ', 's', 't')\n",
      "('s', 't', 'r')\n",
      "('t', 'r', 'e')\n",
      "('r', 'e', 'n')\n",
      "('e', 'n', 'g')\n",
      "('n', 'g', 't')\n",
      "('g', 't', 'h')\n",
      "('t', 'h', '.')\n"
     ]
    }
   ],
   "source": [
    "# Creación de 3-grams carácter por carácter\n",
    "sentence = \"War is peace freedom is slavery ignorance is strength.\"\n",
    "for gram in nltk.ngrams(sentence, 3):\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('who', 'controls', 'the')\n",
      "('controls', 'the', 'past')\n",
      "('the', 'past', 'controls')\n",
      "('past', 'controls', 'the')\n",
      "('controls', 'the', 'future:')\n",
      "('the', 'future:', 'who')\n",
      "('future:', 'who', 'controls')\n",
      "('who', 'controls', 'the')\n",
      "('controls', 'the', 'present')\n",
      "('the', 'present', 'controls')\n",
      "('present', 'controls', 'the')\n",
      "('controls', 'the', 'past.')\n"
     ]
    }
   ],
   "source": [
    "# Creación de 3-grams palabra por palabra\n",
    "sentence = \"who controls the past controls the future: who controls the present controls the past.\"\n",
    "for gram in nltk.ngrams(sentence.split(), 3):\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimando Empíricamente las Probabilidades de un Texto\n",
    "\n",
    "Dado un modelo $n$-gram, estimamos la probabilidad de un *token* $w_n$ de la siguiente manera\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    p(w_k | w_{k-1}, \\ldots, w_{k-n+1}) &= \\frac{C(w_k, w_{k-1}, \\ldots, w_{k-n+1})}{\\sum_{w} C(w, w_{k-1}, \\ldots, w_{k-n+1})}\\\\\n",
    "    &= \\frac{C(w_k, w_{k-1}, \\ldots, w_{k-n+1})}{C(w_{k-1}, \\ldots, w_{k-n+1})}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Donde\n",
    "* $C(\\cdot)$ es la frequencia del $n$-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who',\n",
       " 'controls',\n",
       " 'the',\n",
       " 'past',\n",
       " 'controls',\n",
       " 'the',\n",
       " 'future',\n",
       " 'who',\n",
       " 'controls',\n",
       " 'the',\n",
       " 'present',\n",
       " 'controls',\n",
       " 'the',\n",
       " 'past']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "work_tokenizer = RegexpTokenizer(\"\\w+\")\n",
    "tokens = work_tokenizer.tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('who', 'controls'),\n",
       " ('controls', 'the'),\n",
       " ('the', 'past'),\n",
       " ('past', 'controls'),\n",
       " ('controls', 'the'),\n",
       " ('the', 'future'),\n",
       " ('future', 'who'),\n",
       " ('who', 'controls'),\n",
       " ('controls', 'the'),\n",
       " ('the', 'present'),\n",
       " ('present', 'controls'),\n",
       " ('controls', 'the'),\n",
       " ('the', 'past')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram2 = list(nltk.ngrams(tokens, 2))\n",
    "gram2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['future', 'controls', 'who', 'the', 'present', 'past']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens = list(set(tokens))\n",
    "unique_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo una matriz de frequencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>future</th>\n",
       "      <th>controls</th>\n",
       "      <th>who</th>\n",
       "      <th>the</th>\n",
       "      <th>present</th>\n",
       "      <th>past</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>controls</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>future</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>past</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>present</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          future  controls  who  the  present  past\n",
       "controls     0.0       0.0  0.0  4.0      0.0   0.0\n",
       "future       0.0       0.0  1.0  0.0      0.0   0.0\n",
       "past         0.0       1.0  0.0  0.0      0.0   0.0\n",
       "present      0.0       1.0  0.0  0.0      0.0   0.0\n",
       "the          1.0       0.0  0.0  0.0      1.0   2.0\n",
       "who          0.0       2.0  0.0  0.0      0.0   0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = {tok: Counter([g[:-1] for g in gram2 if g[-1] in tok]) for tok in unique_tokens}\n",
    "counts = pd.DataFrame(counts).fillna(0)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>future</th>\n",
       "      <th>controls</th>\n",
       "      <th>who</th>\n",
       "      <th>the</th>\n",
       "      <th>present</th>\n",
       "      <th>past</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>controls</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>future</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>past</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>present</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          future  controls  who  the  present  past\n",
       "controls    0.00       0.0  0.0  1.0     0.00   0.0\n",
       "future      0.00       0.0  1.0  0.0     0.00   0.0\n",
       "past        0.00       1.0  0.0  0.0     0.00   0.0\n",
       "present     0.00       1.0  0.0  0.0     0.00   0.0\n",
       "the         0.25       0.0  0.0  0.0     0.25   0.5\n",
       "who         0.00       1.0  0.0  0.0     0.00   0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability mass table\n",
    "pm_table = counts / counts.sum(axis=1).values[:, np.newaxis]\n",
    "pm_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the    0.5\n",
       "Name: past, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P('past' | 'the ')\n",
    "pm_table.loc[\"the\", \"past\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>future</th>\n",
       "      <th>controls</th>\n",
       "      <th>who</th>\n",
       "      <th>the</th>\n",
       "      <th>present</th>\n",
       "      <th>past</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     future  controls  who  the  present  past\n",
       "the    0.25       0.0  0.0  0.0     0.25   0.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(w | 'the ')\n",
    "pm_table.loc[\"the\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "future      0.25\n",
       "controls    0.00\n",
       "who         0.00\n",
       "the         0.00\n",
       "present     0.25\n",
       "past        0.50\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Σw P(w | 'the ') = 1\n",
    "pm_table.loc[\"the\", :].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "who    1.0\n",
       "Name: controls, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P('controls' | 'who')\n",
    "pm_table.loc[\"who\", \"controls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "who    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(who U past | controls)\n",
    "pm_table.loc[\"who\", [\"controls\", \"future\"]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:teal\">Ejemplo: 1984</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.gutenberg.org/cache/epub/2000/pg2000.txt\"\n",
    "url = \"http://gutenberg.net.au/ebooks01/0100021.txt\"\n",
    "r = requests.get(url)\n",
    "corpus = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acotamos el texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_book = corpus.find(\"Chapter 1\")\n",
    "end_book = corpus.find(\"End of Project Gutenberg's\")\n",
    "corpus = corpus[init_book: end_book]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "It was a bright cold day in April, and the clocks were striking thirteen.\r\n",
      "Winston Smith, his chin nuzzled into his breast in an effort to escape the\r\n",
      "vile wind, slipped quickly through the glass doors of Victory Mansions,\r\n",
      "though not quickly enough to prevent a swirl of gritty dust from entering\r\n",
      "along with him.\r\n",
      "\r\n",
      "The hallway smelt of boiled cabbage and old rag mats. At one end of it a\r\n",
      "coloured poster, too large for indoor display, had been tacked to the wall.\r\n",
      "It depicted si\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter', '1', 'it', 'was', 'a', 'bright', 'cold', 'day', 'in', 'april']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = work_tokenizer.tokenize(corpus.lower())\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8864"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens = list(set(tokens))\n",
    "len(unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimando Frequencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts(token, gram):\n",
    "    gram_counter = Counter([g[:-1] for g in gram if g[-1] == token])\n",
    "    return (token, gram_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.8 s, sys: 77.8 ms, total: 41.8 s\n",
      "Wall time: 42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gram3 = list(nltk.ngrams(tokens, 3))\n",
    "counts = {tok: value_counts(tok, gram3) for tok in unique_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 245 ms, sys: 93 ms, total: 338 ms\n",
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "gram3 = list(nltk.ngrams(tokens, 3))\n",
    "\n",
    "def value_counts(token):\n",
    "    gram_counter = Counter([g[:-1] for g in gram3 if g[-1] == token])\n",
    "    return (token, gram_counter)\n",
    "\n",
    "pool = Pool(processes=6)\n",
    "res = pool.map(value_counts, unique_tokens)\n",
    "counter = dict(res)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.7 s, sys: 5.68 s, total: 44.4 s\n",
      "Wall time: 46.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Count DataFrame\n",
    "cdf = pd.DataFrame(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando la probabilidad de \n",
    "\n",
    "$$\n",
    "    p(\\texttt{you}, \\texttt{are}, \\texttt{the})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00958057729848568"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p('you')\n",
    "p_a = cdf[\"you\"].sum() / np.nansum(cdf.values)\n",
    "p_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06429277942631058"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p('are' | 'you')\n",
    "p_b = cdf.xs(\"you\", level=1)[\"are\"].sum() / cdf[\"you\"].sum()\n",
    "p_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07692307692307693"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p('the' | 'you', 'are')\n",
    "p_c = cdf.loc[(\"you\", \"are\"), \"the\"] / cdf.loc[(\"you\", \"are\")].sum()\n",
    "p_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00473817%'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = p_a * p_b * p_c\n",
    "format(p, \"0.8%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('you', 'are', 'the'), ('you', 'are', 'the'), ('you', 'are', 'the'), ('you', 'are', 'the'), ('you', 'are', 'the')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.00473817%'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = [v for v in gram3 if v == (\"you\", \"are\", \"the\")]\n",
    "print(r)\n",
    "p = len(r) / len(gram3)\n",
    "format(p, \"0.8%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando un Nuevo Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gram(tokens, gram):\n",
    "    tokens = tuple(tokens)\n",
    "    counts = cdf.loc[tokens].dropna()\n",
    "    probs = counts / counts.sum()\n",
    "    return probs.index , probs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"i am\"\n",
    "\n",
    "for i in range(15):\n",
    "    toks = work_tokenizer.tokenize(sentence)\n",
    "    words, ps = sample_gram(toks[-2:], gram=3)\n",
    "    \n",
    "    seed(1643 + i)\n",
    "    w = choice(words, p=ps)\n",
    "    toks.append(w)\n",
    "    toks.pop(0)\n",
    "\n",
    "    sentence += f\" {w}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am well aware you are finally caught you it will be made clear later in the'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes\n",
    "\n",
    "## Un Clasificador Probabilistico\n",
    "\n",
    "Sea $d=(f_1, \\ldots, f_n)$ un vector de características de un documento $d$, $C = \\{c_k\\}_{k=1}^K$ una colección de clases para un documento.\n",
    "\n",
    "> Dado un documento $d$, queremos estimar la clase a la cuál pertenece $c$\n",
    "\n",
    "El modelo de Naïve Bayes hace dos supociones sobre un documento $d$:\n",
    "1. *Bag of Words assumption*: El orden dentro del documento no importa\n",
    "2. *Naïve Bayes assumption*: Cada característica del modelo es independiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando las dos supociones del modelo, estimamos la clase $c_k$ de un documento de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\hat c &= \\arg\\max_k p(C_k|d) \\\\\n",
    "           &= \\arg\\max_k p(C_k) \\prod_{n=1}^N p(W_n|C_k)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "- Jurafsky, Dan, and James H. Martin. *Speech and Language Processing: an Introduction to Natural Language Processing*, Computational Linguistics, and Speech Recognition. Dorling Kindersley Pvt, Ltd., 2014.\n",
    "\n",
    "- Russell, Stuart J., and Peter Norvig. _Artificial Intelligence: a Modern Approach_. Pearson, 2021."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
